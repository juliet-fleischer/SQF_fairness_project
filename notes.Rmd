---
title: "R Notebook"
output: html_notebook
---

# Defining the PA
race as PA, problems:
- class imbalance, the privileged group is extremely underrepresented in the data
- the PA has more than two levels
possible solutions:
- use BORO as PA instead and dichotomize in (BRONX, QUEENS) : rest
- dichotomize race for class balance instead of sensible context (Black : rest)
- dichotomize race in whie : rest and use a resampling strategy to create more white observations


# General
For all the Yes-No binary variables 1 = yes, 0 = no

# Modelling
be careful about class-imbalance in one potential feature
```{r}
table(sqf.complete.2023$SUMMONS_ISSUED_FLAG)
```



-  naming error (see overleaf)
- look for implementation of further fairness metrics
(calibration, individual fairness, ...)
continue reading this other paper (nuances of fairness metrics ...)

- based on the feature importance race is a minor predictor for being arrested
- I try out differerent groupings for race and grouping d based on skin colour yields the best classical performance metrics (can this be seen as an inidcator that skin colour could influence the decision process?)

- bring the confusion-based fairness metrics in connection with the confusion matrix
(can you define others based on it?)
- move onto the Calibration fairness defs
- do the same for another model with better traditional performance + see how
the fairness metrics behave (change the features, change definition of PA; maybe
we see that the definitions are extremely sensitive to how the PA is defined;
I could limit myself to a subset of the data or dichotomise the PA in different
ways to examine the effects)

# Pick up from here
- put the smallest three categories of race together into one "other" category?
- maybe read literature about data imbalance and how it affects fairness metrics

