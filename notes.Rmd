---
title: "R Notebook"
output: html_notebook
---

# Defining the PA
race as PA, problems:
- class imbalance, the privileged group is extremely underrepresented in the data
- the PA has more than two levels
possible solutions:
- use BORO as PA instead and dichotomize in (BRONX, QUEENS) : rest
- dichotomize race for class balance instead of sensible context (Black : rest)
- dichotomize race in whie : rest and use a resampling strategy to create more white observations


# General
For all the Yes-No binary variables 1 = yes, 0 = no

# Modelling
be careful about class-imbalance in one potential feature
```{r}
table(sqf.complete.2023$SUMMONS_ISSUED_FLAG)
```



-  naming error (see overleaf)
- look for implementation of further fairness metrics
(calibration, individual fairness, ...)
continue reading this other paper (nuances of fairness metrics ...)

- based on the feature importance race is a minor predictor for being arrested
- I try out differerent groupings for race and grouping d based on skin colour yields the best classical performance metrics (can this be seen as an inidcator that skin colour could influence the decision process?)

- bring the confusion-based fairness metrics in connection with the confusion matrix
(can you define others based on it?)
- move onto the Calibration fairness defs
- do the same for another model with better traditional performance + see how
the fairness metrics behave (change the features, change definition of PA; maybe
we see that the definitions are extremely sensitive to how the PA is defined;
I could limit myself to a subset of the data or dichotomise the PA in different
ways to examine the effects)

# Thesis planning

## idea 1
Intro:
ADMs, fairness, COMPAS debate, tranisition to SQF data, questions around the data so far
Contributions of the thesis:
- synthesising how fairness has been studied for this data
- compare and come to a conclusion which is the best one?
Chapters:
- background and context of the data
- SQF Fairness for arrest (Through Lens of Causality, Data Transparency)
Lets take a step back and say that the discrimination is the stop itself. This also makes
more sense in the context of an ADM that should help us decide whether to stop someone in the first place (for higher hit-crates and more fairness)
- SQF Fairness for weapon detection (Residual Unfairness, Bias in Bias out, maybe Precinct or Prejudice and Selective labels problem)
- comparison
How are selective labels and differential sampling bias related?
Why don't we simply say the fact that so many more black people are stopped than white people
given a completely different race distribution in overall NYC is enough evidence for racial bias?
Because could be that crime rates are really higher among blacks, ...?

Conclusion:
- know the type of bias in your situation, this should affect the fairness
analysis you do (choice of definition and method)

## idea 1 (refinec)
General Flow of Your Seminar Thesis:

Part 1
Fairness metrics in ML: Group, Individual, Causality - intuition, nuances, running example?, mention extentions to LLMs, NNs, ...
Fairness methods: Pre, In, Post - idea, example (but not so in detail)
Feedback Loop + context: bringing metrics and methods together and explaining that data context and data quality is important
--> make all the argument I want to make in general

Part 2
Context of the Stop, Question, and Frisk (SQF) dataset
Problem that comes with SQF
How normal fairness metrics work in this context and what they show
How the literature tackles this problem
--> illustrate my arguments from part 1 with SQF dataset


Paper 1 (Kallus & Zhou, 2018): Introduce residual unfairness and "bias from biased data."
Empirical Evaluation of Bias in the SQF Dataset:

Paper 2 (Rambachan & Roth, 2019): Examine whether SQF-trained algorithms necessarily produce biased outcomes.
Contextualize this within your understanding of the SQF dataset structure and fairness definitions (e.g., demographic parity, equalized odds).
Detection and Mitigation of Bias:

Paper 3 (Ravishankar et al., 2023): Introduce tools for detecting and mitigating sampling bias in datasets like SQF.
Conclusion:

Recap the insights gained from each paper.
Summarize the current state of research and potential avenues for further work, e.g., refining models for fairness without sacrificing predictive performance.


## idea 2
Intro:
ADMs, fairness, COMPAS debate, tranisition to SQF data, plethora of fairness metrics
Contributions of the thesis:
- we examine how different fairness definitions work in this context
- conclude which ones are most suitable
Chapters:
- intro to fairness definitions and data situation and task
- Group metrics on SQF
- Individual metrics on SQF
- maybe causal metrics on SQF
Conlusion:
- be aware of what each fairness definition comes with and know your data + context
to asses whether the definition is suitable


# pick up from here
use chatgpt to brainstorm how i could work with the data
--> idk if i can replicate this paper, i dont get the math behind hardt et al.
--> but i got the theory behind the residual fairness paper, so i can outline this def

calculate the propensity weights for each group of borough and race
implement the linear program from hardt et al
summarize results




