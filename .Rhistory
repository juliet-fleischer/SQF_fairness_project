calcGroupwiseMetrics(base_mrs_punitive, tsk_arrest, predictions_arrested)
calcGroupwiseMetrics(base_mrs_assistive, tsk_arrest, predictions_arrested)
calcGroupwiseMetrics(base_mrs_other, tsk_arrest, predictions_arrested)
predictions_arrested
source("~/Library/Mobile Documents/com~apple~CloudDocs/Documents/01_Studium/13_Jahr_03/21_TrustML/NYPD_SQF_data/program/functions.R")
calcGroupwiseMetrics(base_mrs_punitive, tsk_arrest, predictions_arrested)
groupwise_measures
predictions
all.equal(predictions, predictions_arrested)
source("~/Library/Mobile Documents/com~apple~CloudDocs/Documents/01_Studium/13_Jahr_03/21_TrustML/NYPD_SQF_data/program/functions.R")
calcGroupwiseMetrics(base_mrs_punitive, tsk_arrest, predictions_arrested)
calcGroupwiseMetrics(base_mrs_assistive, tsk_arrest, predictions_arrested)
calcGroupwiseMetrics(base_mrs_other, tsk_arrest, predictions_arrested)
head(predictions_arrested)
head(splits_arrested$test)
predictions_arrested$response
predictions_arrested$data()
predictions_arrested$data
predictions_dt <- as.data.table(predictions_arrested)
predictions_dt
splits_arrested$test
imputed_data_arrested[splits_arrested$test, .(SUSPECT_SEX)]
pa.data <- imputed_data_arrested[splits_arrested$test, .(SUSPECT_SEX)]
predictions_dt <- cbind(predictions_dt, pa.data)
predictions_dt
predictions_dt <- as.data.table(predictions_arrested)
pa.data <- imputed_data_arrested[splits_arrested$test, .(SUSPECT_SEX)]
predictions_dt
pa.data
predictions_dt <- cbind(pa.data, predictions_dt)
predictions_dt
# Independence:
predictions_dt[, .(sum(response == "1") / .N), by = "SUSPECT_SEX"]
table(predictions_dt$SUSPECT_SEX)
predictions_dt[, .(sum(response == "1"))]
predictions_dt[, .(sum(response == "1")), by = "SUSPECT_SEX"]
736 / 5247
104 / 338
# Independence:
predictions_dt[, .(sum(response == "1") / .N), by = "SUSPECT_SEX"]
# Independence:
predictions_dt[, "Stat_parity" = .(sum(response == "1") / .N), by = "SUSPECT_SEX"]
# Independence:
predictions_dt[, .(sum(response == "1") / .N), by = "SUSPECT_SEX"]
# Independence:
stat.parity <- predictions_dt[, .(sum(response == "1") / .N), by = "SUSPECT_SEX"]
stat.parity
calcGroupwiseMetrics(base_mrs_punitive, tsk_arrest, predictions_arrested)
# initialize fairness measure
# punitive
fairness_msr_punitive <- msrs(c("fairness.fpr","fairness.tnr","fairness.ppv"))
# "fairness.fdr" (not implemented but should be as equivalent for fairness.fomr)
predictions_arrested$score(fairness_msr_punitive, task = tsk_frisk)
table(imputed_data_arrested$SUSPECT_SEX)
calcGroupwiseMetrics(base_mrs_punitive, tsk_arrest, predictions_arrested)
# Define multiple base measures
base_mrs_assistive <- list(
fnr = msr("classif.fnr"),
tpr = msr("classif.tpr"),
npv = msr("classif.npv"),
fomr = msr("classif.fomr")
)
calcGroupwiseMetrics(base_mrs_assistive, tsk_arrest, predictions_arrested)
# initialize fairness measure
# punitive
fairness_msr_punitive <- msrs(c("fairness.fpr","fairness.tnr","fairness.ppv"))
# "fairness.fdr" (not implemented but should be as equivalent for fairness.fomr)
predictions_arrested$score(fairness_msr_punitive, task = tsk_frisk)
# assistive
fairness_msr_assistive <- msrs(c("fairness.fnr","fairness.tpr", "fairness.npv",
"fairness.fomr"))
predictions$score(fairness_msr_assistive, task = tsk_frisk)
calcGroupwiseMetrics(base_mrs_punitive, tsk_arrest, predictions_arrested)
head(predictions_dt)
# Score-based metrics:
# balance for positive class
predictions_dt[, .(mean(prob.1)), by = c("truth", "SUSPECT_SEX")]
# Score-based metrics:
# balance for positive class
balance.for.positive.class <- predictions_dt[, .(mean(prob.1)), by = c("truth", "SUSPECT_SEX")][truth == "1"]
balance.for.positive.class
# Score-based metrics:
# balance for positive class
blnc.f.pos.clss <- predictions_dt[, .(mean(prob.1)), by = c("truth", "SUSPECT_SEX")][truth == "1"]
blnc.f.neg.clss <- predictions_dt[, .(mean(prob.0)), by = c("truth", "SUSPECT_SEX")][truth == "0"]
blnc.f.pos.clss
blnc.f.neg.clss
hist(predictions_dt)
hist(predictions_dt$prob.1)
hist(predictions_dt$prob.0)
# Score-ased metrics - Sufficiency:
# bin the prediction scores into categories from 0 to 1 by 0.1
predictions_dt[, bin := cut(prob.1, breaks = seq(0, 1, by = 0.1))]
predictions_dt
min(predictions_dt$prob.1)
View(predictions_dt)
seq(0, 1, by = 0.1)
# Score-based metrics - Sufficiency:
# bin the prediction scores into categories from 0 to 1 by 0.1
breaks <- seq(0, 1, by = 0.1)
breaks - c(0.1, rep(0, 10))
# Score-based metrics - Sufficiency:
# bin the prediction scores into categories from 0 to 1 by 0.1
breaks <- seq(0, 1, by = 0.1) - c(0.1, rep(0, 10))
breaks
# Score-based metrics - Sufficiency:
# bin the prediction scores into categories from 0 to 1 by 0.1
custom.breaks <- seq(0, 1, by = 0.1) - c(0.1, rep(0, 10))
predictions_dt[, bin := cut(prob.1, breaks = custom.breaks)]
predictions_dt
predictions_dt[sort(predictions_dt$prob.1)]
predictions_dt[,sort(predictions_dt$prob.1)]
View(predictions_dt)
glimpse(predictions_dt)
calibration <- predictions_dt[, sum(truth == "1"), by = c("bin", "SUSPECT_SEX")]
calibration
calibration <- predictions_dt[, sum(truth == "1") / .N, by = c("bin", "SUSPECT_SEX")]
calibration <- predictions_dt[, sum(truth == "1") / .N, by = c("bin", "SUSPECT_SEX")][sort(bin)]
calibration <- predictions_dt[, sum(truth == "1") / .N, by = c("bin", "SUSPECT_SEX")][sort(V1)]
calibration
calibration <- predictions_dt[, sum(truth == "1") / .N, by = c("bin", "SUSPECT_SEX")]
calibration
calibration <- predictions_dt[, sum(truth == "1") / .N, by = c("bin", "SUSPECT_SEX"), on = "bin"]
calibration
str(calibration)
calibration <- predictions_dt[, sum(truth == "1") / .N, by = c("bin", "SUSPECT_SEX")]
View(calibration)
# Define bins for predicted probabilities
custom.breaks <- seq(0, 1, by = 0.1)
predictions_dt[, bin := cut(prob.1, breaks = custom.breaks, include.lowest = TRUE)]
calibration
# Compute observed positive rates per bin and group
calibration.2 <- predictions_dt[, .(
observed_rate = mean(truth == "1"),
predicted_rate = mean(prob.1)  # Avg predicted score in the bin
), by = .(bin, SUSPECT_SEX)]
calibration.2
View(calibration.2)
# Check well-calibration:
# Observed rates (Y=1) should match predicted rates (S) across all bins and groups
well_calibrated <- all.equal(calibration.2$observed_rate, calibration.2$predicted_rate)
print(well_calibrated)
ggplot(calibration.2, aes(x = predicted_rate, y = observed_rate, color = SUSPECT_SEX)) +
geom_point() +
geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black") +
labs(title = "Well-Calibration Check", x = "Predicted Rate", y = "Observed Rate")
glimpse(imputed_data_arrested)
# FTU
imputed_data_arrested1 <- copy(imputed_data_arrested)
# FTU
imputed_data_arrested2 <- copy(imputed_data_arrested)
imputed_data_arrested_2[, SUSPECT_SEX := NULL]
glimpse(imputed_data_arrested2)
remove(imputed_data_arrested2)
remove(imputed_data_arrested_2)
remove(imputed_data_arrested1)
# FTU
imputed_data_arrested2 <- copy(imputed_data_arrested)
imputed_data_arrested2[, SUSPECT_SEX := NULL]
glimpse(imputed_data_arrested2)
splits_arrested$train
task_train <- tsk_arrest$clone()
# Remove the PA column for training
task_train$select(setdiff(task_train$feature_names, "SUSPECT_SEX"))
# Train the model on the modified task
lrn_rf$train(task_train, row_ids = splits_arrested$train)
# make predictions on the test set
predictions.FTU <- lrn_rf$predict(tsk_arrest, row_ids = splits_arrested$test)
# make predictions on the test set
predictions.FTU <- lrn_rf$predict(task_train, row_ids = splits_arrested$test)
as.data.table(predictions.FTU)
setDT(predictions.FTU)
predictions.FTU_dt <- cbind(pa.data, as.data.table(predictions.FTU))
predictions.FTU_dt
predictions_dt
# make a copy of the predictions data frame but with reversed sex column
predictions.FTU_dt_reversed <- copy(predictions.FTU_dt)
# make a copy of the test data but with reversed sex column
test.data.reversed <- copy(imputed_data_arrested[splits_arrested$test])
test.data.reversed
# reverse the sex olumn
test.data.reversed[, SUSPECT_SEX := ifelse(SUSPECT_SEX == "1", "0", "1")]
table(test.data.reversed$SUSPECT_SEX)
# make predictions on the reversed test data
predictions_reversed <- lrn_rf$predict(as_task_classif(test.data.reversed, target = "SUSPECT_ARRESTED_FLAG",
positive = "1", id = "arrest"), row_ids = 1:nrow(test.data.reversed))
?predict
# Clone the task
task_train <- tsk_arrest$clone()
# Remove the PA column for training
task_train$select(setdiff(task_train$feature_names, "SUSPECT_SEX"))
# Train the model on the modified task
lrn_rf$train(task_train, row_ids = splits_arrested$train)
# make predictions on the test set
predictions.FTU <- lrn_rf$predict(task_train, row_ids = splits_arrested$test)
predictions.FTU_dt <- cbind(pa.data, as.data.table(predictions.FTU))
# make a copy of the test data but with reversed sex column
test.data.original <- copy(imputed_data_arrested[splits_arrested$test])
# reverse the sex olumn
test.data.reversed <- copy(test.data.original)
test.data.reversed[, SUSPECT_SEX := ifelse(SUSPECT_SEX == "1", "0", "1")]
# add ID column
test.data.original[, ID := .I]
test.data.reversed[, ID := .I]
glimpse(test.data.original)
glimpse(test.data.reversed)
# predict on original data
predictions.original <- lrn_rf$predict_newdata(test.data.original)
# predict on reversed data
predictions.reversed <- lrn_rf$predict_newdata(test.data.reversed)
# Convert predictions to data.tables
predictions_original_dt <- as.data.table(predictions_original)
predictions_reversed_dt <- as.data.table(predictions_reversed)
# Convert predictions to data.tables
predictions_original_dt <- as.data.table(predictions.original)
predictions_reversed_dt <- as.data.table(predictions.reversed)
predictions_original_dt
predictions_reversed_dt
# Merge predictions by ID
comparison <- merge(predictions_original_dt, predictions_reversed_dt, by = "row_ids", suffixes = c("_original", "_reversed"))
comparison
# Compare the predictions for each pair
comparison[, prediction_same := response_original == response_reversed]
# View discrepancies
print(comparison[prediction_same == FALSE])
l1 <- as_learner(po("reweighing_wts") %>>% lrn("classif.ranger"))
lrn_rf$id <- "ranger"
l1 <- as_learner(po("reweighing_wts") %>>% lrn("classif.ranger"))
l1$id <- "reweight"
l2 = as_learner(po("learner_cv", lrn("classif.ranger")) %>>%
po("EOd"))
l2$id = "EOd"
# preprocess by collapsing factors
l3 = as_learner(po("collapsefactors") %>>% lrn("classif.fairzlrm"))
l3$id = "fairzlrm"
install.packages("linprog")
install.packages("fairml")
library(fairml)
library(linprog)
# load learners
lrn_rf$id <- "ranger"
l1 <- as_learner(po("reweighing_wts") %>>% lrn("classif.ranger"))
l1$id <- "reweight"
l2 = as_learner(po("learner_cv", lrn("classif.ranger")) %>>%
po("EOd"))
l2$id = "EOd"
# preprocess by collapsing factors
l3 = as_learner(po("collapsefactors") %>>% lrn("classif.fairzlrm"))
l3$id = "fairzlrm"
# run experiment
lrns = list(lrn_rpart, l1, l2, l3)
# run experiment
lrns = list(lrn_rf, l1, l2, l3)
bmr = benchmark(benchmark_grid(tsk_arrest, lrns, rsmp("cv", folds = 2)))
install.packages("CVXR")
library(CVXR)
meas = msrs(c("classif.acc", "fairness.eod"))
bmr$aggregate(meas)[,
.(learner_id, classif.acc, fairness.equalized_odds)]
bmr = benchmark(benchmark_grid(tsk_arrest, lrns, rsmp("cv", folds = 2)))
meas = msrs(c("classif.acc", "fairness.eod"))
bmr$aggregate(meas)[,
.(learner_id, classif.acc, fairness.equalized_odds)]
source("~/Documents/NYPD_SQF_data/setup.R")
glimpse(sqf.2023)
sqf.2023 <- read_excel("data/sqf-2023.xlsx")
setDT(sqf.2023)
n <- nrow(sqf.2023)
sqf.2023[sqf.2023 == "(null)"] <- NA
targets <- c("SUSPECT_ARRESTED_FLAG", "SEARCHED_FLAG", "FRISKED_FLAG")
protected.a <- c("SUSPECT_SEX", "SUSPECT_RACE_DESCRIPTION")
glimpse(sqf.2023)
# convert all the columns that end on FLAG or FLG to factor
flag.cols <- grep("FLAG$|FLG$", names(sqf.2023))
sqf.2023[, (flag.cols) := lapply(.SD, as.factor), .SDcols = flag.cols]
glimpse(sqf.2023)
# delete a few columns that wouldn't make sense as features
cols.to.remove <- c("STOP_ID", "STOP_FRISK_DATE", "STOP_FRISK_TIME", "DEMEANOR_OF_PERSON_STOPPED",
"SUSPECT_OTHER_DESCRIPTION", "STOP_LOCATION_FULL_ADDRESS", "STOP_LOCATION_X",
"STOP_LOCATION_Y", "STOP_LOCATION_APARTMENT")
sqf.2023[ , (cols.to.remove) := NULL])]
sqf.2023[ , (cols.to.remove) := NULL]
glimpse(sqf.2023)
# convert al remaining character columns to factor
char.cols <- which(sapply(sqf.2023, is.character))
char.cols
sqf.2023 <- read_excel("data/sqf-2023.xlsx")
setDT(sqf.2023)
n <- nrow(sqf.2023)
sqf.2023[sqf.2023 == "(null)"] <- NA
# delete a few columns that wouldn't make sense as features
cols.to.remove <- c("STOP_ID", "STOP_FRISK_DATE", "STOP_FRISK_TIME", "DEMEANOR_OF_PERSON_STOPPED",
"SUSPECT_OTHER_DESCRIPTION", "STOP_LOCATION_FULL_ADDRESS", "STOP_LOCATION_X",
"STOP_LOCATION_Y", "STOP_LOCATION_APARTMENT")
sqf.2023[ , (cols.to.remove) := NULL]
# convert al columns with numbers to numeric
sqf.2023[, (col.names) := lapply(.SD, function(x) {
if (all(is.na(x) | grepl("[[:digit:]]+", x))) as.numeric(x) else x
}), .SDcols = col.names]
# convert all the columns that end on FLAG or FLG to factor
flag.cols <- grep("FLAG$|FLG$", names(sqf.2023))
sqf.2023[, (flag.cols) := lapply(.SD, as.factor), .SDcols = flag.cols]
# convert al remaining character columns to factor
char.cols <- which(sapply(sqf.2023, is.character))
glimpse(sqf.2023)
grepl("[[:digit:]]+", "804")
# convert al remaining character columns to factor
char.cols <- which(sapply(sqf.2023, is.character))
sqf.2023[, (char.cols) := lapply(.SD, as.factor), .SDcols = char.cols]
glimpse(sqf.2023)
library(glmnet)
x <- model.matrix(SUSPECT_ARRESTED ~ ., data = sqf.2023)
x <- model.matrix(ARRESTED_FLAG ~ ., data = sqf.2023)
x <- model.matrix(SUSPECT_ARRESTED_FLAG ~ ., data = sqf.2023)
y <- sqf.2023$SUSPECT_ARRESTED_FLAG
lasso.cv <- cv.glmnet(x, y, family = binomial(link = "logit"), alpha = 1)
set.seed(123)
x <- model.matrix(SUSPECT_ARRESTED_FLAG ~ ., data = sqf.2023)
apply(sqf.2023, 2, function(x) (length(unique(x))))
res <- apply(sqf.2023, 2, function(x) (length(unique(x))))
which(res == 1)
# delete a few columns that wouldn't make sense as features
cols.to.remove <- c("STOP_ID", "STOP_FRISK_DATE", "STOP_FRISK_TIME", "DEMEANOR_OF_PERSON_STOPPED",
"SUSPECT_OTHER_DESCRIPTION", "STOP_LOCATION_FULL_ADDRESS", "STOP_LOCATION_X",
"STOP_LOCATION_Y", "STOP_LOCATION_APARTMENT", "YEAR2", "RECORD_STATUS_CODE")
sqf.2023[ , (cols.to.remove) := NULL]
# fit a logistic regression with LASSO regularization
set.seed(123)
x <- model.matrix(SUSPECT_ARRESTED_FLAG ~ ., data = sqf.2023)
res <- apply(sqf.2023, 2, function(x) (length(unique(x))))
which(res == 1)
levels(sqf.2023)
levels(sqf.2023$SUSPECT_ARREST_FLAG)
levels(sqf.2023$SUSPECT_ARREST_FLAG)
str(sqf.2023$SUSPECT_ARREST_FLAG)
str(sqf.2023$SUSPECT_ARRESTED_FLAG)
source("~/Documents/NYPD_SQF_data/program/data_cleaning.R")
set.seed(123)
x <- model.matrix(SUSPECT_ARRESTED_FLAG ~ ., data = sqf.2023)
res <- apply(sqf.2023, 2, function(x) (length(levels(x))))
which(res == 1)
res
levels(sqf.2023$LOCATION_IN_OUT_CODE)
length(levels(sqf.2023$LOCATION_IN_OUT_CODE))
sqf.2023 <- read_excel("data/sqf-2023.xlsx")
setDT(sqf.2023)
n <- nrow(sqf.2023)
sqf.2023[sqf.2023 == "(null)"] <- NA
# delete a few columns that wouldn't make sense as features
cols.to.remove <- c("STOP_ID", "STOP_FRISK_DATE", "STOP_FRISK_TIME", "DEMEANOR_OF_PERSON_STOPPED",
"SUSPECT_OTHER_DESCRIPTION", "STOP_LOCATION_FULL_ADDRESS", "STOP_LOCATION_X",
"STOP_LOCATION_Y", "STOP_LOCATION_APARTMENT", "YEAR2", "RECORD_STATUS_CODE")
sqf.2023[ , (cols.to.remove) := NULL]
# convert al columns with numbers to numeric
sqf.2023[, (col.names) := lapply(.SD, function(x) {
if (all(is.na(x) | grepl("[[:digit:]]+", x))) as.numeric(x) else x
}), .SDcols = col.names]
# convert all the columns that end on FLAG or FLG to factor
flag.cols <- grep("FLAG$|FLG$", names(sqf.2023))
sqf.2023[, (flag.cols) := lapply(.SD, as.factor), .SDcols = flag.cols]
# convert al remaining character columns to factor
char.cols <- which(sapply(sqf.2023, is.character))
sqf.2023[, (char.cols) := lapply(.SD, as.factor), .SDcols = char.cols]
# fit a logistic regression with LASSO regularization
set.seed(123)
x <- model.matrix(SUSPECT_ARRESTED_FLAG ~ ., data = sqf.2023)
sapply(lapply(sqf.2023, unique), length)
res <- sapply(lapply(sqf.2023, unique), length)
which(res == 1)
which(res == 2)
sort(res)
library(glmnet)
sqf.2023 <- read_excel("data/sqf-2023.xlsx")
setDT(sqf.2023)
n <- nrow(sqf.2023)
sqf.2023[sqf.2023 == "(null)"] <- NA
# delete a few columns that wouldn't make sense as features
cols.to.remove <- c("STOP_ID", "STOP_FRISK_DATE", "STOP_FRISK_TIME", "DEMEANOR_OF_PERSON_STOPPED",
"SUSPECT_OTHER_DESCRIPTION", "STOP_LOCATION_FULL_ADDRESS", "STOP_LOCATION_X",
"STOP_LOCATION_Y", "STOP_LOCATION_APARTMENT", "YEAR2", "RECORD_STATUS_CODE")
sqf.2023[ , (cols.to.remove) := NULL]
# convert al columns with numbers to numeric
sqf.2023[, (col.names) := lapply(.SD, function(x) {
if (all(is.na(x) | grepl("[[:digit:]]+", x))) as.numeric(x) else x
}), .SDcols = col.names]
# convert all the columns that end on FLAG or FLG to factor
flag.cols <- grep("FLAG$|FLG$", names(sqf.2023))
sqf.2023[, (flag.cols) := lapply(.SD, as.factor), .SDcols = flag.cols]
# convert al remaining character columns to factor
char.cols <- which(sapply(sqf.2023, is.character))
sqf.2023[, (char.cols) := lapply(.SD, as.factor), .SDcols = char.cols]
# fit a logistic regression with LASSO regularization
set.seed(123)
x <- model.matrix(SUSPECT_ARRESTED_FLAG ~ ., data = sqf.2023)
unique(sqf.2023$SUPERVISING_ACTION_CORRESPONDING_ACTIVITY_LOG_ENTRY_REVIEWED)
# fit a logistic regression with LASSO regularization
set.seed(123)
x <- model.matrix(SUSPECT_ARRESTED_FLAG ~ ., data = sqf.2023)[, -1]
x
x <- model.matrix(SUSPECT_ARRESTED_FLAG ~ ., data = sqf.2023)
x
sqf.2023[!is.na(sqf.2023$SUSPECT_ARRESTED_FLAG), ]
sqf.2023 <- sqf.2023[!is.na(sqf.2023$SUSPECT_ARRESTED_FLAG), ]
sapply(sqf.2023, function(x) {
if (is.factor(x)) {
table(x)
} else {
NULL
}
})
source("~/Documents/NYPD_SQF_data/program/data_cleaning.R")
x <- model.matrix(SUSPECT_ARRESTED_FLAG ~ ., data = sqf.2023)
sapply(sqf.2023, function(x) {
if (is.factor(x)) {
table(x)
} else {
NULL
}
})
?as.formula
lasso.form <- as.formula("SUSPECT_ARRESTED_FLAG ~ .")
LIBRARY(smurf)
library(smurf)
library(glmnet)
library(smurf)
sqf.2023 <- read_excel("data/sqf-2023.xlsx")
setDT(sqf.2023)
n <- nrow(sqf.2023)
sqf.2023[sqf.2023 == "(null)"] <- NA
glimpse(sqf.2023)
source("~/Documents/NYPD_SQF_data/program/data_cleaning.R")
x <- model.matrix(SUSPECT_ARRESTED_FLAG ~ ., data = sqf.2023)
sqf.2023 <- droplevels(sqf.2023)
x <- model.matrix(SUSPECT_ARRESTED_FLAG ~ ., data = sqf.2023)
colSums(is.na(sqf.2023))
sqf.2023 <- na.omit(sqf.2023)
x <- model.matrix(SUSPECT_ARRESTED_FLAG ~ ., data = sqf.2023)
colSums(is.na(sqf.2023))
source("~/Documents/NYPD_SQF_data/program/data_cleaning.R")
sqf.2023 <- droplevels(sqf.2023)
colSums(is.na(sqf.2023))
source("~/Documents/NYPD_SQF_data/program/data_cleaning.R")
x <- model.matrix(SUSPECT_ARRESTED_FLAG ~ ., data = sqf.2023)
colSums(is.na(sqf.2023))
source("~/Documents/NYPD_SQF_data/program/data_cleaning.R")
x <- model.matrix(SUSPECT_ARRESTED_FLAG ~ ., data = sqf.2023)
y <- sqf.2023$SUSPECT_ARRESTED_FLAG
lasso.cv <- cv.glmnet(x, y, family = binomial(link = "logit"), alpha = 1)
x
dim(x)
sqf.2023 <- na.omit(sqf.2023)
x <- model.matrix(SUSPECT_ARRESTED_FLAG ~ ., data = sqf.2023)
y <- sqf.2023$SUSPECT_ARRESTED_FLAG
lasso.cv <- cv.glmnet(x, y, family = binomial(link = "logit"), alpha = 1)
lasso.cv$lambda
lasso.cv$lambda.min
lambda.lasso <- lasso.cv$lambda.min
lasso.fit <- glmnet(x, y, family = binomial(link = "logit"), alpha = 1, lambda = lambda.lasso)
summary(lasso.fit)
coef(lasso.fit)
library(glmnet)
library(smurf)
sqf.2023 <- read_excel("data/sqf-2023.xlsx")
setDT(sqf.2023)
n <- nrow(sqf.2023)
sqf.2023[sqf.2023 == "(null)"] <- NA
# delete a few columns that wouldn't make sense as features
cols.to.remove <- c("STOP_ID", "STOP_FRISK_DATE", "STOP_FRISK_TIME", "DEMEANOR_OF_PERSON_STOPPED",
"SUSPECT_OTHER_DESCRIPTION", "STOP_LOCATION_FULL_ADDRESS", "STOP_LOCATION_X",
"STOP_LOCATION_Y", "STOP_LOCATION_APARTMENT", "YEAR2", "RECORD_STATUS_CODE", "STOP_LOCATION_STREET_NAME")
sqf.2023[ , (cols.to.remove) := NULL]
# convert al columns with numbers to numeric
sqf.2023[, (col.names) := lapply(.SD, function(x) {
if (all(is.na(x) | grepl("[[:digit:]]+", x))) as.numeric(x) else x
}), .SDcols = col.names]
# convert all the columns that end on FLAG or FLG to factor
flag.cols <- grep("FLAG$|FLG$", names(sqf.2023))
sqf.2023[, (flag.cols) := lapply(.SD, as.factor), .SDcols = flag.cols]
# convert al remaining character columns to factor
char.cols <- which(sapply(sqf.2023, is.character))
sqf.2023[, (char.cols) := lapply(.SD, as.factor), .SDcols = char.cols]
# fit a logistic regression with LASSO regularization
set.seed(123)
sqf.2023 <- droplevels(sqf.2023)
colSums(is.na(sqf.2023))
sqf.2023 <- na.omit(sqf.2023)
library(glmnet)
library(smurf)
sqf.2023 <- read_excel("data/sqf-2023.xlsx")
setDT(sqf.2023)
n <- nrow(sqf.2023)
sqf.2023[sqf.2023 == "(null)"] <- NA
# delete a few columns that wouldn't make sense as features
cols.to.remove <- c("STOP_ID", "STOP_FRISK_DATE", "STOP_FRISK_TIME", "DEMEANOR_OF_PERSON_STOPPED",
"SUSPECT_OTHER_DESCRIPTION", "STOP_LOCATION_FULL_ADDRESS", "STOP_LOCATION_X",
"STOP_LOCATION_Y", "STOP_LOCATION_APARTMENT", "YEAR2", "RECORD_STATUS_CODE", "STOP_LOCATION_STREET_NAME")
sqf.2023[ , (cols.to.remove) := NULL]
# convert al columns with numbers to numeric
sqf.2023[, (col.names) := lapply(.SD, function(x) {
if (all(is.na(x) | grepl("[[:digit:]]+", x))) as.numeric(x) else x
}), .SDcols = col.names]
# convert all the columns that end on FLAG or FLG to factor
flag.cols <- grep("FLAG$|FLG$", names(sqf.2023))
sqf.2023[, (flag.cols) := lapply(.SD, as.factor), .SDcols = flag.cols]
# convert al remaining character columns to factor
char.cols <- which(sapply(sqf.2023, is.character))
sqf.2023[, (char.cols) := lapply(.SD, as.factor), .SDcols = char.cols]
# fit a logistic regression with LASSO regularization
set.seed(123)
sqf.2023 <- droplevels(sqf.2023)
colSums(is.na(sqf.2023))
sort(colSums(is.na(sqf.2023)))
