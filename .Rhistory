library(readxl)
library(ggplot2)
library(pROC)
library(tidyverse)
library(mlr3verse)
library(mlr3fairness)
library(mice)
library(checkmate)
library(iml)
source("program/functions.R")
source("program/data_cleaning.R")
source("program/pre_training.R")
glimpse(imputed_data_arrested)
glimpse(imputed_data_frisked)
seed()
?seed
get.seed()
source("~/Library/Mobile Documents/com~apple~CloudDocs/Documents/01_Studium/13_Jahr_03/21_TrustML/NYPD_SQF_data/program/modelling.R")
source("~/Library/Mobile Documents/com~apple~CloudDocs/Documents/01_Studium/13_Jahr_03/21_TrustML/NYPD_SQF_data/program/modelling.R")
source("~/Library/Mobile Documents/com~apple~CloudDocs/Documents/01_Studium/13_Jahr_03/21_TrustML/NYPD_SQF_data/program/mlr3_fairness.R")
imputed_data_arrested
# initialize a learner
p <- ncol(imputed_data_frisked) - 1
lrn_rf <- lrn("classif.ranger", mtry = ceiling(p / 2), predict_type = "prob", importance = "impurity")
# construct a resampling strategy
cv5 <- rsmp("cv", folds = 5)
# set performance measures
measures <- msrs(c("classif.acc", "classif.bbrier", "classif.auc"))
### --- frisked specific --- ###
# remove ID column for training
imputed_data_frisked <- imputed_data_frisked[, -1]
# initialize a classification task
tsk_frisk <- as_task_classif(imputed_data_frisked, target = "FRISKED_FLAG",
positive = "1", id = "frisk")
# specify the PA
tsk_frisk$col_roles$pta <- "SUSPECT_SEX"
# create train train split
splits_frisk <- partition(tsk_frisk)
# train
lrn_rf$train(tsk_frisk, row_ids = splits_frisk$train)
# make predictions on test data
predictions_frisk <- lrn_rf$predict(tsk_frisk, row_ids = splits_frisk$test)
tsk_frisk()
tsk_frisk
tsk_arrest
lrn_rf
calcGroupwiseMetrics <- function(base_mrs, task, predictions) {
# assert whether base_mrs is a list containing measure mlr3 objects, or a single mlr3 measure
assert_task(task)
# Create groupwise metrics
groupwise_measures <- lapply(base_mrs, function(b) groupwise_metrics(b, task = task))
# Compute scores for each groupwise metric
groupwise_results <- lapply(groupwise_measures, function(m) predictions$score(m, task))
# Combine results into a data frame
groupwise_results_df <- do.call(cbind, groupwise_results)
# Inspect results
print(groupwise_results_df)
}
calcGroupwiseMetrics(base_mrs_punitive, tsk_frisk, predictions_frisk)
calcGroupwiseMetrics(base_mrs_assistive, tsk_frisk, predictions_frisk)
calcGroupwiseMetrics(base_mrs_other, tsk_frisk, predictions_frisk)
calcGroupwiseMetrics(base_mrs_punitive, tsk_arrest, predictions_arrested)
calcGroupwiseMetrics(base_mrs_assistive, tsk_arrest, predictions_arrested)
calcGroupwiseMetrics(base_mrs_other, tsk_arrest, predictions_arrested)
#
table(imputed_data_arrested$SUSPECT_SEX)
imputed_data_frisked |> group_by(SUSPECT_SEX) |> summarise(sum(FRISKED_FLAG) / nrow(imputed_data_frisked))
table(FRISKED_FLAG ~SUSPECT_SEX, data = imputed_data_frisked)
xtabs(FRISKED_FLAG ~SUSPECT_SEX, data = imputed_data_frisked)
10586 / nrwo(imputed_data_frisked)
10586 / nrow(imputed_data_frisked)
314 / nrow(imputed_data_frisked)
imputed_data_arrested |> group_by(SUSPECT_SEX) |> summarise(sum(SUSPECT_ARRESTED_FLAG) / nrow(imputed_data_arrested))
glimpse(sqf.2023)
xtabs(FRISKED_FLAG ~ SUSPECT_SEX, data = sqf.2023)
sqf.2023 <- read_excel("data/sqf-2023.xlsx")
setDT(sqf.2023)
n <- nrow(sqf.2023)
sqf.2023[sqf.2023 == "(null)"] <- NA
# remove all officer columns
pattern.officer <- "[:alpha:]*_OFFICER_[:alpha:]*"
officer.cols <- grep(pattern.officer, names(sqf.2023))
sqf.2023[, (officer.cols) := NULL]
# remove all location columns except STOP_LOCATION_BORO_NAME
pattern.location <- "[:alpha:]*_LOCATION_[:alpha:]*"
location.cols <- grep(pattern.location, names(sqf.2023))
sqf.2023[, (location.cols[-length(location.cols)]) := NULL]
# remove all columns that start with PHYSICAL_FORCE
pattern.force <- "PHYSICAL_FORCE[:alpha:]*"
force.cols <- grep(pattern.force, names(sqf.2023))
sqf.2023[, (force.cols) := NULL]
# remove all columns relted to summons
pattern.summons <- "SUMMONS[:alpha:]*"
summons.cols <- grep(pattern.summons, names(sqf.2023))
sqf.2023[, (summons.cols) := NULL]
# remove all columns without specifc pattern
sqf.2023$YEAR2 <- NULL
sqf.2023$STOP_FRISK_DATE <- NULL
sqf.2023$RECORD_STATUS_CODE <- NULL
sqf.2023$DEMEANOR_OF_PERSON_STOPPED <- NULL
sqf.2023$SUPERVISING_ACTION_CORRESPONDING_ACTIVITY_LOG_ENTRY_REVIEWED <- NULL
sqf.2023$JURISDICTION_CODE <- NULL
sqf.2023$OFFICER_NOT_EXPLAINED_STOP_DESCRIPTION <- NULL
sqf.2023$SUSPECT_OTHER_DESCRIPTION <- NULL
sqf.2023$SUSPECT_ARREST_OFFENSE <- NULL
sqf.2023$SUSPECTED_CRIME_DESCRIPTION <- NULL
# from column 23 to 42 set all the NAs to "N"
sqf.2023[, (19:38) := lapply(.SD, function(x) {
ifelse(is.na(x), "N", x)
}), .SDcols = 19:38]
glimpse(sqf.2023)
# convert all the columns that end on FLAG or FLG to factor
flag.cols <- grep("FLAG$|FLG$", names(sqf.2023))
sqf.2023[, (flag.cols) := lapply(.SD, as.factor), .SDcols = flag.cols]
glimpse(sqf.2023)
# go through each column an check whether it matches alpha or digit
# if it matches digit, convert it to numeric
col.names <- names(sqf.2023)[-c(1,2)]
# Apply the transformation to all columns that match the pattern
sqf.2023[, (col.names) := lapply(.SD, function(x) {
if (all(is.na(x) | grepl("[[:digit:]]+", x))) as.numeric(x) else x
}), .SDcols = col.names]
glimpse(sqf.2023)
# convert all potential target columns to numeric
sqf.2023[ , (targets) := lapply(.SD,function(x) { ifelse(x == "Y", 1, 0)}), .SDcols = targets]
table(sqf.2023$FRISKED_FLAG)
table(sqf.2023$SUSPECT_ARRESTED_FLAG)
# convert sex to numeric 0 = female, 1 = male
sqf.2023[, SUSPECT_SEX := ifelse(SUSPECT_SEX == "FEMALE", 0, 1)]
table(sqf.2023$SUSPECT_SEX)
source("~/Library/Mobile Documents/com~apple~CloudDocs/Documents/01_Studium/13_Jahr_03/21_TrustML/NYPD_SQF_data/program/data_cleaning.R")
xtabs(FRISKED_FLAG ~ SUSPECT_SEX, data = sqf.2023)
imputed_data_frisked |>
group_by(SUSPECT_SEX) |>
summarise(n = n(), prop = mean(FRISKED_FLAG))
imputed_data_frisked |>
group_by(SUSPECT_SEX) |>
summarise(sum(FRISKED_FLAG) / nrow(imputed_data_frisked))
sqf.2023 |>
group_by(SUSPECT_SEX) |>
summarise(sum(FRISKED_FLAG) / nrow(sqf.2023))
imputed_data_arrested |>
group_by(SUSPECT_SEX) |>
summarise(sum(SUSPECT_ARRESTED_FLAG) / nrow(imputed_data_arrested))
sqf.2023 |>
group_by(SUSPECT_SEX) |>
summarise(sum(SUSPECT_ARRESTED_FLAG) / nrow(sqf.2023))
0.0236 / 0.265
calcGroupwiseMetrics(base_mrs_punitive, tsk_arrest, predictions_arrested)
calcGroupwiseMetrics(base_mrs_assistive, tsk_arrest, predictions_arrested)
calcGroupwiseMetrics(base_mrs_other, tsk_arrest, predictions_arrested)
tsk_arrest
table(sqf.2023$SEARCHED_FLAG)
table(sqf.2023$FRISKED_FLAG)
table(sqf.2023$SUSPECT_ARRESTED_FLAG)
# for searched
sqf.2023 |>
group_by(SUSPECT_SEX) |>
summarise(sum(SEARCHED_FLAG) / nrow(sqf.2023))
sqf.2023 |>
group_by(SUSPECT_SEX) |>
summarise(sum(SUSPECT_ARRESTED_FLAG) / nrow(sqf.2023))
4888 / 12036
6024 / 10900
6773/ 10151
imputed_data_frisked |>
group_by(SUSPECT_SEX) |>
summarise(sum(FRISKED_FLAG) / n()))
imputed_data_frisked |>
group_by(SUSPECT_SEX) |>
summarise(sum(FRISKED_FLAG) / n())
sqf.2023 |>
group_by(SUSPECT_SEX) |>
summarise(sum(FRISKED_FLAG) / n())
# proportion of arrested by sex in the imputed and original data is virtually the same
# for arrested too
imputed_data_arrested |>
group_by(SUSPECT_SEX) |>
summarise(sum(SUSPECT_ARRESTED_FLAG) / n())
sqf.2023 |>
group_by(SUSPECT_SEX) |>
summarise(sum(SUSPECT_ARRESTED_FLAG) / n())
# for searched
sqf.2023 |>
group_by(SUSPECT_SEX) |>
summarise(sum(SEARCHED_FLAG) / n())
imputed_data_searched |>
group_by(SUSPECT_SEX) |>
summarise(sum(SEARCHED_FLAG) / n())
### --- searched specific --- ###
imputed_data_searched <- imputed_data_searched[, -1]
glimpse(imputed_data_searched)
table(imputed_data_searched$SUSPECT_SEX)
tsk_searched <- as_task_classif(imputed_data_searched, target = "SEARCHED_FLAG",
positive = "1", id = "search")
# specify the PA
tsk_searched$col_roles$pta <- "SUSPECT_SEX"
# create train train split
splits_searched <- partition(tsk_searched)
# train
lrn_rf$train(tsk_searched, row_ids = splits_searched$train)
# make predictions on test data
predictions_searched <- lrn_rf$predict(tsk_searched, row_ids = splits_searched$test)
calcGroupwiseMetrics(base_mrs_punitive, tsk_searched, predictions_searched)
calcGroupwiseMetrics(base_mrs_assistive, tsk_searched, predictions_searched)
calcGroupwiseMetrics(base_mrs_other, tsk_searched, predictions_searched)
# analyse feature importance for search task
searched_x <- tsk_searched$data(rows = splits_searched$test, cols = tsk_searched$feature_names)
searched_y <- tsk_searched$data(rows = splits_searched$test, cols = tsk_searched$target_names)
predictor_searched <- Predictor$new(lrn_rf, data = searched_x, y = searched_y)
importance_searched <- FeatureImp$new(predictor_searched, loss = "ce")
importance_searched$plot()
# possible dichotomizations of race
imputed_data_arrested_2 <- imputed_data_arrested |>
mutate(race_group = ifelse(SUSPECT_RACE_DESCRIPTION %in% c("BLACK", "BLACK HISPANIC"), "c", "w")) |>
select(-SUSPECT_RACE_DESCRIPTION)
# possible dichotomizations of race
imputed_data_arrested_2 <- imputed_data_arrested |>
mutate(race_group = ifelse(SUSPECT_RACE_DESCRIPTION %in% c("BLACK", "BLACK HISPANIC"), "c", "w"))
glimpse(imputed_data_arrested_2)
table(imputed_data_arrested_2$race_group)
imputed_data_arrested_2$SUSPECT_RACE_DESCRIPTION <- NULL
glimpse(imputed_data_arrested)
### --- ARRESTED with RACE as PA --- ###
task_arrested_2 <- as_task_classif(imputed_data_arrested_2, target = "SUSPECT_ARRESTED_FLAG",
positive = "1", id = "arrest")
task_arrested_2$col_roles$pta <- "race_group"
splits_arrested_2 <- partition(task_arrested_2)
lrn_rf$train(task_arrested_2, row_ids = splits_arrested_2$train)
predictions_arrested_2 <- lrn_rf$predict(task_arrested_2, row_ids = splits_arrested_2$test)
remove(sqf.2023)
remove(searched_x)
remove(imputed_data_searched)
remove(imputed_data_frisked)
remove(imputed_data_full)
remove(splits_frisk)
remove(splits_searched)
calcGroupwiseMetrics(base_mrs_punitive, task_arrested_2, predictions_arrested_2)
calcGroupwiseMetrics(base_mrs_assistive, task_arrested_2, predictions_arrested_2)
calcGroupwiseMetrics(base_mrs_other, task_arrested_2, predictions_arrested_2)
# analyse feature importance for arrested_2
arrested_2_x <- task_arrested_2$data(rows = splits_arrested_2$test, cols = task_arrested_2$feature_names)
arrested_2_y <- task_arrested_2$data(rows = splits_arrested_2$test, cols = task_arrested_2$target_names)
predictor_arrested_2 <- Predictor$new(lrn_rf, data = arrested_2_x, y = arrested_2_y)
importance_arrested_2 <- FeatureImp$new(predictor_arrested_2, loss = "ce")
importance_arrested_2$plot()
calcGroupwiseMetrics(base_mrs_punitive, tsk_arrest, predictions_arrested)
calcGroupwiseMetrics(base_mrs_assistive, tsk_arrest, predictions_arrested)
calcGroupwiseMetrics(base_mrs_other, tsk_arrest, predictions_arrested)
calcGroupwiseMetrics(base_mrs_punitive, tsk_arrest, predictions_arrested)
calcGroupwiseMetrics(base_mrs_assistive, tsk_arrest, predictions_arrested)
calcGroupwiseMetrics(base_mrs_other, tsk_arrest, predictions_arrested)
predictions_arrested
source("~/Library/Mobile Documents/com~apple~CloudDocs/Documents/01_Studium/13_Jahr_03/21_TrustML/NYPD_SQF_data/program/functions.R")
calcGroupwiseMetrics(base_mrs_punitive, tsk_arrest, predictions_arrested)
groupwise_measures
predictions
all.equal(predictions, predictions_arrested)
source("~/Library/Mobile Documents/com~apple~CloudDocs/Documents/01_Studium/13_Jahr_03/21_TrustML/NYPD_SQF_data/program/functions.R")
calcGroupwiseMetrics(base_mrs_punitive, tsk_arrest, predictions_arrested)
calcGroupwiseMetrics(base_mrs_assistive, tsk_arrest, predictions_arrested)
calcGroupwiseMetrics(base_mrs_other, tsk_arrest, predictions_arrested)
head(predictions_arrested)
head(splits_arrested$test)
predictions_arrested$response
predictions_arrested$data()
predictions_arrested$data
predictions_dt <- as.data.table(predictions_arrested)
predictions_dt
splits_arrested$test
imputed_data_arrested[splits_arrested$test, .(SUSPECT_SEX)]
pa.data <- imputed_data_arrested[splits_arrested$test, .(SUSPECT_SEX)]
predictions_dt <- cbind(predictions_dt, pa.data)
predictions_dt
predictions_dt <- as.data.table(predictions_arrested)
pa.data <- imputed_data_arrested[splits_arrested$test, .(SUSPECT_SEX)]
predictions_dt
pa.data
predictions_dt <- cbind(pa.data, predictions_dt)
predictions_dt
# Independence:
predictions_dt[, .(sum(response == "1") / .N), by = "SUSPECT_SEX"]
table(predictions_dt$SUSPECT_SEX)
predictions_dt[, .(sum(response == "1"))]
predictions_dt[, .(sum(response == "1")), by = "SUSPECT_SEX"]
736 / 5247
104 / 338
# Independence:
predictions_dt[, .(sum(response == "1") / .N), by = "SUSPECT_SEX"]
# Independence:
predictions_dt[, "Stat_parity" = .(sum(response == "1") / .N), by = "SUSPECT_SEX"]
# Independence:
predictions_dt[, .(sum(response == "1") / .N), by = "SUSPECT_SEX"]
# Independence:
stat.parity <- predictions_dt[, .(sum(response == "1") / .N), by = "SUSPECT_SEX"]
stat.parity
calcGroupwiseMetrics(base_mrs_punitive, tsk_arrest, predictions_arrested)
# initialize fairness measure
# punitive
fairness_msr_punitive <- msrs(c("fairness.fpr","fairness.tnr","fairness.ppv"))
# "fairness.fdr" (not implemented but should be as equivalent for fairness.fomr)
predictions_arrested$score(fairness_msr_punitive, task = tsk_frisk)
table(imputed_data_arrested$SUSPECT_SEX)
calcGroupwiseMetrics(base_mrs_punitive, tsk_arrest, predictions_arrested)
# Define multiple base measures
base_mrs_assistive <- list(
fnr = msr("classif.fnr"),
tpr = msr("classif.tpr"),
npv = msr("classif.npv"),
fomr = msr("classif.fomr")
)
calcGroupwiseMetrics(base_mrs_assistive, tsk_arrest, predictions_arrested)
# initialize fairness measure
# punitive
fairness_msr_punitive <- msrs(c("fairness.fpr","fairness.tnr","fairness.ppv"))
# "fairness.fdr" (not implemented but should be as equivalent for fairness.fomr)
predictions_arrested$score(fairness_msr_punitive, task = tsk_frisk)
# assistive
fairness_msr_assistive <- msrs(c("fairness.fnr","fairness.tpr", "fairness.npv",
"fairness.fomr"))
predictions$score(fairness_msr_assistive, task = tsk_frisk)
calcGroupwiseMetrics(base_mrs_punitive, tsk_arrest, predictions_arrested)
head(predictions_dt)
# Score-based metrics:
# balance for positive class
predictions_dt[, .(mean(prob.1)), by = c("truth", "SUSPECT_SEX")]
# Score-based metrics:
# balance for positive class
balance.for.positive.class <- predictions_dt[, .(mean(prob.1)), by = c("truth", "SUSPECT_SEX")][truth == "1"]
balance.for.positive.class
# Score-based metrics:
# balance for positive class
blnc.f.pos.clss <- predictions_dt[, .(mean(prob.1)), by = c("truth", "SUSPECT_SEX")][truth == "1"]
blnc.f.neg.clss <- predictions_dt[, .(mean(prob.0)), by = c("truth", "SUSPECT_SEX")][truth == "0"]
blnc.f.pos.clss
blnc.f.neg.clss
hist(predictions_dt)
hist(predictions_dt$prob.1)
hist(predictions_dt$prob.0)
# Score-ased metrics - Sufficiency:
# bin the prediction scores into categories from 0 to 1 by 0.1
predictions_dt[, bin := cut(prob.1, breaks = seq(0, 1, by = 0.1))]
predictions_dt
min(predictions_dt$prob.1)
View(predictions_dt)
seq(0, 1, by = 0.1)
# Score-based metrics - Sufficiency:
# bin the prediction scores into categories from 0 to 1 by 0.1
breaks <- seq(0, 1, by = 0.1)
breaks - c(0.1, rep(0, 10))
# Score-based metrics - Sufficiency:
# bin the prediction scores into categories from 0 to 1 by 0.1
breaks <- seq(0, 1, by = 0.1) - c(0.1, rep(0, 10))
breaks
# Score-based metrics - Sufficiency:
# bin the prediction scores into categories from 0 to 1 by 0.1
custom.breaks <- seq(0, 1, by = 0.1) - c(0.1, rep(0, 10))
predictions_dt[, bin := cut(prob.1, breaks = custom.breaks)]
predictions_dt
predictions_dt[sort(predictions_dt$prob.1)]
predictions_dt[,sort(predictions_dt$prob.1)]
View(predictions_dt)
glimpse(predictions_dt)
calibration <- predictions_dt[, sum(truth == "1"), by = c("bin", "SUSPECT_SEX")]
calibration
calibration <- predictions_dt[, sum(truth == "1") / .N, by = c("bin", "SUSPECT_SEX")]
calibration <- predictions_dt[, sum(truth == "1") / .N, by = c("bin", "SUSPECT_SEX")][sort(bin)]
calibration <- predictions_dt[, sum(truth == "1") / .N, by = c("bin", "SUSPECT_SEX")][sort(V1)]
calibration
calibration <- predictions_dt[, sum(truth == "1") / .N, by = c("bin", "SUSPECT_SEX")]
calibration
calibration <- predictions_dt[, sum(truth == "1") / .N, by = c("bin", "SUSPECT_SEX"), on = "bin"]
calibration
str(calibration)
calibration <- predictions_dt[, sum(truth == "1") / .N, by = c("bin", "SUSPECT_SEX")]
View(calibration)
# Define bins for predicted probabilities
custom.breaks <- seq(0, 1, by = 0.1)
predictions_dt[, bin := cut(prob.1, breaks = custom.breaks, include.lowest = TRUE)]
calibration
# Compute observed positive rates per bin and group
calibration.2 <- predictions_dt[, .(
observed_rate = mean(truth == "1"),
predicted_rate = mean(prob.1)  # Avg predicted score in the bin
), by = .(bin, SUSPECT_SEX)]
calibration.2
View(calibration.2)
# Check well-calibration:
# Observed rates (Y=1) should match predicted rates (S) across all bins and groups
well_calibrated <- all.equal(calibration.2$observed_rate, calibration.2$predicted_rate)
print(well_calibrated)
ggplot(calibration.2, aes(x = predicted_rate, y = observed_rate, color = SUSPECT_SEX)) +
geom_point() +
geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black") +
labs(title = "Well-Calibration Check", x = "Predicted Rate", y = "Observed Rate")
glimpse(imputed_data_arrested)
# FTU
imputed_data_arrested1 <- copy(imputed_data_arrested)
# FTU
imputed_data_arrested2 <- copy(imputed_data_arrested)
imputed_data_arrested_2[, SUSPECT_SEX := NULL]
glimpse(imputed_data_arrested2)
remove(imputed_data_arrested2)
remove(imputed_data_arrested_2)
remove(imputed_data_arrested1)
# FTU
imputed_data_arrested2 <- copy(imputed_data_arrested)
imputed_data_arrested2[, SUSPECT_SEX := NULL]
glimpse(imputed_data_arrested2)
splits_arrested$train
task_train <- tsk_arrest$clone()
# Remove the PA column for training
task_train$select(setdiff(task_train$feature_names, "SUSPECT_SEX"))
# Train the model on the modified task
lrn_rf$train(task_train, row_ids = splits_arrested$train)
# make predictions on the test set
predictions.FTU <- lrn_rf$predict(tsk_arrest, row_ids = splits_arrested$test)
# make predictions on the test set
predictions.FTU <- lrn_rf$predict(task_train, row_ids = splits_arrested$test)
as.data.table(predictions.FTU)
setDT(predictions.FTU)
predictions.FTU_dt <- cbind(pa.data, as.data.table(predictions.FTU))
predictions.FTU_dt
predictions_dt
# make a copy of the predictions data frame but with reversed sex column
predictions.FTU_dt_reversed <- copy(predictions.FTU_dt)
# make a copy of the test data but with reversed sex column
test.data.reversed <- copy(imputed_data_arrested[splits_arrested$test])
test.data.reversed
# reverse the sex olumn
test.data.reversed[, SUSPECT_SEX := ifelse(SUSPECT_SEX == "1", "0", "1")]
table(test.data.reversed$SUSPECT_SEX)
# make predictions on the reversed test data
predictions_reversed <- lrn_rf$predict(as_task_classif(test.data.reversed, target = "SUSPECT_ARRESTED_FLAG",
positive = "1", id = "arrest"), row_ids = 1:nrow(test.data.reversed))
?predict
# Clone the task
task_train <- tsk_arrest$clone()
# Remove the PA column for training
task_train$select(setdiff(task_train$feature_names, "SUSPECT_SEX"))
# Train the model on the modified task
lrn_rf$train(task_train, row_ids = splits_arrested$train)
# make predictions on the test set
predictions.FTU <- lrn_rf$predict(task_train, row_ids = splits_arrested$test)
predictions.FTU_dt <- cbind(pa.data, as.data.table(predictions.FTU))
# make a copy of the test data but with reversed sex column
test.data.original <- copy(imputed_data_arrested[splits_arrested$test])
# reverse the sex olumn
test.data.reversed <- copy(test.data.original)
test.data.reversed[, SUSPECT_SEX := ifelse(SUSPECT_SEX == "1", "0", "1")]
# add ID column
test.data.original[, ID := .I]
test.data.reversed[, ID := .I]
glimpse(test.data.original)
glimpse(test.data.reversed)
# predict on original data
predictions.original <- lrn_rf$predict_newdata(test.data.original)
# predict on reversed data
predictions.reversed <- lrn_rf$predict_newdata(test.data.reversed)
# Convert predictions to data.tables
predictions_original_dt <- as.data.table(predictions_original)
predictions_reversed_dt <- as.data.table(predictions_reversed)
# Convert predictions to data.tables
predictions_original_dt <- as.data.table(predictions.original)
predictions_reversed_dt <- as.data.table(predictions.reversed)
predictions_original_dt
predictions_reversed_dt
# Merge predictions by ID
comparison <- merge(predictions_original_dt, predictions_reversed_dt, by = "row_ids", suffixes = c("_original", "_reversed"))
comparison
# Compare the predictions for each pair
comparison[, prediction_same := response_original == response_reversed]
# View discrepancies
print(comparison[prediction_same == FALSE])
l1 <- as_learner(po("reweighing_wts") %>>% lrn("classif.ranger"))
lrn_rf$id <- "ranger"
l1 <- as_learner(po("reweighing_wts") %>>% lrn("classif.ranger"))
l1$id <- "reweight"
l2 = as_learner(po("learner_cv", lrn("classif.ranger")) %>>%
po("EOd"))
l2$id = "EOd"
# preprocess by collapsing factors
l3 = as_learner(po("collapsefactors") %>>% lrn("classif.fairzlrm"))
l3$id = "fairzlrm"
install.packages("linprog")
install.packages("fairml")
library(fairml)
library(linprog)
# load learners
lrn_rf$id <- "ranger"
l1 <- as_learner(po("reweighing_wts") %>>% lrn("classif.ranger"))
l1$id <- "reweight"
l2 = as_learner(po("learner_cv", lrn("classif.ranger")) %>>%
po("EOd"))
l2$id = "EOd"
# preprocess by collapsing factors
l3 = as_learner(po("collapsefactors") %>>% lrn("classif.fairzlrm"))
l3$id = "fairzlrm"
# run experiment
lrns = list(lrn_rpart, l1, l2, l3)
# run experiment
lrns = list(lrn_rf, l1, l2, l3)
bmr = benchmark(benchmark_grid(tsk_arrest, lrns, rsmp("cv", folds = 2)))
install.packages("CVXR")
library(CVXR)
meas = msrs(c("classif.acc", "fairness.eod"))
bmr$aggregate(meas)[,
.(learner_id, classif.acc, fairness.equalized_odds)]
bmr = benchmark(benchmark_grid(tsk_arrest, lrns, rsmp("cv", folds = 2)))
meas = msrs(c("classif.acc", "fairness.eod"))
bmr$aggregate(meas)[,
.(learner_id, classif.acc, fairness.equalized_odds)]
