\relax 
\abx@aux@refcontext{nyt/global//global/global}
\abx@aux@cite{0}{verma2018}
\abx@aux@segm{0}{0}{verma2018}
\abx@aux@cite{0}{caton2024}
\abx@aux@segm{0}{0}{caton2024}
\abx@aux@cite{0}{caton2024}
\abx@aux@segm{0}{0}{caton2024}
\abx@aux@page{1}{1}
\@writefile{toc}{\contentsline {section}{\numberline {1}Fairness Metrics \blx@tocontentsinit {0}\parencite {verma2018}}{1}{}\protected@file@percent }
\abx@aux@cite{0}{mehrabi2022}
\abx@aux@segm{0}{0}{mehrabi2022}
\abx@aux@cite{0}{mehrabi2022}
\abx@aux@segm{0}{0}{mehrabi2022}
\@writefile{toc}{\contentsline {section}{\numberline {2}Fairness Methods}{2}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Fairness methods can be applied at different stages of the machine learning pipeline\blx@tocontentsinit {0}\parencite {caton2024}.}}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Sources of bias and the feedback loop}{2}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Bias can come into the process at any stage of the data, algorithm, and user feedback loop\blx@tocontentsinit {0}\parencite {mehrabi2022}.}}{2}{}\protected@file@percent }
\abx@aux@page{6}{2}
\abx@aux@page{7}{2}
\abx@aux@page{8}{2}
\abx@aux@read@bbl@mdfivesum{6D855000CB0AED309591345B70D382C5}
\abx@aux@defaultrefcontext{0}{caton2024}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{mehrabi2022}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{verma2018}{nyt/global//global/global}
\gdef \@abspage@last{2}
