Fairness in machine learning has attracted considerable attention in recent years, leading to a rich literature of definitions and evaluation frameworks. Several works provide broad overviews of these definitions. For example, \cite{verma2018} offer a comprehensive overview of the most popular fairness metrics, accompanied by a case study on the Adult dataset. \cite{castelnovo2022} highlights their nuances and subtleties. The work of \cite{corbett-davies} and of \cite{barocas} serves as detailed resources that offer deeper insights into common fallacies in fairML.

Beside the definition of fairness a major branch of research has concerned itself with the design of bias migitation techniques. \cite{mehrabi2022} and \cite{caton2024} provide a detailed review. Additionally, the fairness chapter in the \cite{mlr3_book} serves as an accessible introduction to the practical implementation of fairness metrics and methods.

Beyond these more general works, a number of studies from the fields fairML, Statistics, and Economics, have focused on the SQF dataset. Building on the previously mentioned work of \cite{gelman2007}, \cite{goel2016} advance the statistical methods used in the former study to further to support the claim that non-white individuals are disproportionately targeted by New York's police.
\cite{Khademi2019FADMELC} examined fairness in SQF from a causal perspective. Their study supports the complexity of this topic as they arrive at divergent conclusions, depending on which of their metrics they use.\\
In the course of this paper it will become clearer that selection bias is a major concern for the SQF data. The effects of selection bias on fairness and potential ways to counteract them have been studied by \cite{Lakkaraju2017SLPEAPPU} and \cite{favier2023}.
The other studies that explicitly use SQF \cite{Badr2022DTFANSP, RambachanBBOEFW, kallus2018} will be more closely examined in the final chapter of this paper.

