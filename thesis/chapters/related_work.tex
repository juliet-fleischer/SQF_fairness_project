Fairness in machine learning has attracted considerable attention in recent years, leading to a rich literature of definitions and evaluation frameworks. Several works provide broad overviews of these definitions. For example, \cite{verma2018} offers a comprehensive overview of the most popular fairness metrics and \cite{castelnovo2022} highlights their nuances in a compact manner. \cite{corbett-davies} and \cite{barocas} serve as detailed resources that offer deeper insights into common fallacies in fairML. \\

Beside the definition of fairness a major area of research is the design of bias migitation techniques to which \cite{mehrabi2022} and \cite{caton2024} provide an extensive overview. Additionally, the \texttt{mlr3book} serves as an accessible introduction to the practical implementation of fairness metrics.

Beyond these general discussions, a number of studies from the fields fairML, Statistics, and Economics, have focused on the stop, question, and frisk (SQF) dataset. \cite{gelman2007} is one of the earlier works that provides both historical context and a sophisticated statistical analysis to show racial disparities in the policing strategy. Building on this, \cite{goel2016} advance the statistical methods further to support the claim that non-white individuals are disproportionately targeted by the New York police.

Fairness in SQF has been examined from a causal perspective by \cite{Khademi2019FADMELC}. Their study supports the complexity of measuring fairness in SQF as their different metrics come to divergent fairness conclusions. In the course of this paper it will become clearer that selection bias is a major concern for the SQF data. The effects of selection bias on fairness and potential ways to counteract them have been studied by \cite{Lakkaraju2017SLPEAPPU} and \cite{favier2023}.
The other studies that explicitly use SQF \cite{Badr2022DTFANSP, RambachanBBOEFW, kallus2018} will be more closely examined in the final chapter of this paper.

Advocating for more diversity in the datasets used for fairness research additionally \cite{Fabris_2022} recommend the dataset as a valuable resource.

% fairness (in SQF) really depends on the perspective you take! What task do train? What covariates do you take into account?
% How do you want to deploy the algorithm in the future? 