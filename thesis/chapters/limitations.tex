
% Why did our fairness experiment did not show any substantial disparities?\\
% By predicting the arrest of a person we asked a different fairness questions. Fairness in SQF can bee seen as a two-stage problem. The firs stage: was the person stopped? The second stage: what was the result of the stop? For the whole picture it might be better to go in this order. Our tasks jump directly to the second stage. This is not a mistake per se, but one should be aware that these analyses do not reflect the whole process but only a part of it.\\
% On top of this, the mechanisms behind the selection bias in SQF is twisted in the sense that the historically discriminated group is \textit{more present} in the data. Often the situation is that disadvantaged groups form underrepresented minorities, thus the algorithm oversees them and performs worse on them. In the SQF data, however, the algorithm has plenty of observations from PoC to learn from and less from white people.

The SQF data presents interesting questions and challenges. In our examination of fairness in SQF, we placed particular emphasis on selection bias and its impact on the fairness assessment. Future studies could explore other forms of bias that may be relevant to this dataset and examine how they influence the fairness of classifiers. One notable example is historical bias, which may play a significant role here.\par
Moreover, it would be valuable to investigate if and how the fairness audit changes, if race is not aggregated into a binary PA but is instead treated a multi-class variable. This approach could lead to different fairness conclusions and provide a more nuanced perspective. However, in this context, class imbalance within the protected attribute would become more pronounced, introducing new research challenges.\par
Through our work, we have demonstrated that before implementing any fairness intervention, it is essential to first formulate a clear and well-defined fairness question. There is a fundamental difference between asking whether stop-and-frisk as a whole is fair or whether a classifier trained to predict the arrest of a person is fair.
The way we frame the question can shape the design of entirely different algorithmic tasks and fairness analyses.\par
After conducting a detailed fairness audit, experimenting with various models, and reviewing multiple studies, our answer to "Is the Stop, Question, and Frisk practice fair?" remains: it is complex.


