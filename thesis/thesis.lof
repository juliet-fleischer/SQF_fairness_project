\contentsline {figure}{\numberline {1}{\ignorespaces The \textit {data, algorithm, and user interaction feedback loop} as described by \blx@tocontentsinit {0}\cite {mehrabi2022}. Different categories of bias can be introduced at each stage of the process.\relax }}{10}{figure.caption.12}%
\contentsline {figure}{\numberline {2}{\ignorespaces Bar plot comparing the distribution of ethnic groups across boroughs in the SQF 2023 and NYC from 2020 Census (left). On the right a comparison of the estimated borough-wise crime rate per 100,000 citizens with the ethnic distribution of SQF stops.\relax }}{11}{figure.caption.13}%
\contentsline {figure}{\numberline {3}{\ignorespaces Comparison of learners with respect to classification accuracy (x-axis) and equal opportunity (y-axis) across (dots) and aggregated over (crosses) five folds.\relax }}{13}{figure.caption.15}%
\contentsline {figure}{\numberline {4}{\ignorespaces Fairness prediction density plot (left) showing the density of predictions for the positive class split by "PoC" and "White" individuals. The metrics comparison barplot (right) displays the model's absolute differences across the specified metrics.\relax }}{14}{figure.caption.16}%
\contentsline {figure}{\numberline {5}{\ignorespaces Selection bias in the SQF data, as conceptualized by \blx@tocontentsinit {0}\cite {kallus2018}. The true label is only known for the stopped individuals $(Z = 1)$.\relax }}{17}{figure.caption.19}%
